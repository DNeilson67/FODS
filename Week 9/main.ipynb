{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the toy dataset\n",
    "bc = load_breast_cancer()\n",
    "\n",
    "# Create a DataFrame\n",
    "bc_df = pd.DataFrame(data=bc.data, columns=bc.feature_names)\n",
    "\n",
    "# Add the target variable (class) to the DataFrame\n",
    "bc_df['target'] = bc.target\n",
    "\n",
    "# Display the DataFrame\n",
    "print(bc_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans\n",
      "Silhouette Score: 0.6467638371962151\n",
      "Davies-Bouldin Index: 0.6329050458971559\n",
      "Rand Score: 0.5390726905036369\n",
      "Calinski and Harabasz Score: 1246.2597348622987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=\"auto\").fit(bc_df)\n",
    "kmeans_labels = kmeans.labels_\n",
    "true_labels = bc.target\n",
    "\n",
    "# Evaluation Methods\n",
    "silhouette_avg1 = silhouette_score(bc_df, kmeans_labels)\n",
    "dbi_score1 = davies_bouldin_score(bc_df, kmeans_labels)\n",
    "rand_score1 = adjusted_rand_score(true_labels, kmeans_labels)\n",
    "ch_score1 = calinski_harabasz_score(bc_df, kmeans_labels)\n",
    "\n",
    "print(\"KMeans\")\n",
    "print(\"Silhouette Score:\", silhouette_avg1)\n",
    "print(\"Davies-Bouldin Index:\", dbi_score1)\n",
    "print(\"Rand Score:\", rand_score1)\n",
    "print(\"Calinski and Harabasz Score:\", ch_score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affinity Propagation\n",
      "Silhouette Score: 0.029075299464434805\n",
      "Davies-Bouldin Index: 0.09339040693413933\n",
      "Rand Score: 0.00023987188987162304\n",
      "Calinski and Harabasz Score: 15577.954135952754\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "af = AffinityPropagation(preference=-50, random_state=0).fit(bc_df)\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "labels = af.labels_\n",
    "labels_true = bc.target\n",
    "\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "silhouette_avg1 = silhouette_score(bc_df, labels)\n",
    "dbi_score1 = davies_bouldin_score(bc_df, labels)\n",
    "rand_score1 = adjusted_rand_score(labels_true, labels)\n",
    "ch_score1 = calinski_harabasz_score(bc_df, labels)\n",
    "\n",
    "print(\"Affinity Propagation\")\n",
    "print(\"Silhouette Score:\", silhouette_avg1)\n",
    "print(\"Davies-Bouldin Index:\", dbi_score1)\n",
    "print(\"Rand Score:\", rand_score1)\n",
    "print(\"Calinski and Harabasz Score:\", ch_score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 0\n",
      "Estimated number of noise points: 569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "x = StandardScaler().fit_transform(bc_df)\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(x)\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of estimated clusters : 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "x = StandardScaler().fit_transform(bc_df)\n",
    "bandwidth = estimate_bandwidth(x, quantile=0.2, n_samples=500)\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(x)\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)\n",
    "\n",
    "print(\"number of estimated clusters : %d\" % n_clusters_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
